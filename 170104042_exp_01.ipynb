{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "170104042_exp_01.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDojGN7ZWp7s",
        "outputId": "ddff53cf-74a8-435f-d17a-5290508e4d26"
      },
      "source": [
        "#Download Dataset\n",
        "\n",
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "drive_id = '1txyKhs1Zt5AKswGGK9VI_jE0JNHuQT85'\n",
        "d_path ='/content/Data_A.zip'\n",
        "\n",
        "gdd.download_file_from_google_drive(file_id=drive_id , dest_path=d_path, unzip = True)\n",
        "\n",
        "drive_id = '1TLiVh2jKUUQZyhudPoEQmTRscQnLxo9g'\n",
        "d_path ='/content/Data_2.zip'\n",
        "\n",
        "gdd.download_file_from_google_drive(file_id=drive_id , dest_path=d_path, unzip = True)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading 1txyKhs1Zt5AKswGGK9VI_jE0JNHuQT85 into /content/Data_A.zip... Done.\n",
            "Unzipping...Done.\n",
            "Downloading 1TLiVh2jKUUQZyhudPoEQmTRscQnLxo9g into /content/Data_2.zip... Done.\n",
            "Unzipping...Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIMJvQ4RYLLY"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as dsets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GtuqwL9FFhS"
      },
      "source": [
        "Task - Dataset A experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHrY052OY2zb"
      },
      "source": [
        "# Hyperparameters\n",
        "\n",
        "batch_size = 20\n",
        "num_iters = 20000\n",
        "input_dim = 180*180 # num_features = 180*180\n",
        "num_hidden = 200 # num of hidden nodes\n",
        "output_dim = 10\n",
        "\n",
        "learning_rate = 0.01  # More power so we can learn faster! previously it was 0.001\n",
        "\n",
        "# Device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "XgYeFDf0iw1N",
        "outputId": "4dd3272c-0531-45f3-be27-56403bf27a24"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/training-a.csv')\n",
        "df = df[['filename','digit']]\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>digit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>a00000.png</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a00001.png</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>a00002.png</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>a00003.png</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>a00004.png</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     filename  digit\n",
              "0  a00000.png      5\n",
              "1  a00001.png      3\n",
              "2  a00002.png      1\n",
              "3  a00003.png      7\n",
              "4  a00004.png      0"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_4foakNjG99"
      },
      "source": [
        "import os\n",
        "path = '/content/training-a/'\n",
        "for index,row in df.iterrows():\n",
        "  new_path=path+str(row['digit'])\n",
        "  if(os.path.isdir(new_path)):\n",
        "    os.rename(path+row['filename'],new_path+'/'+row['filename'])\n",
        "  else:\n",
        "    os.makedirs(new_path )\n",
        "    os.rename(path+row['filename'],new_path+'/'+row['filename'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtSXz1MIZd-S"
      },
      "source": [
        "'''\n",
        "LOADING DATASET\n",
        "'''\n",
        "transform = transforms.Compose([\n",
        "                                transforms.Grayscale(),                                 \n",
        "                                transforms.ToTensor() \n",
        "                                ])\n",
        " \n",
        "full_dataset = dsets.ImageFolder(root='/content/training-a',transform= transform )\n",
        "\n",
        "torch.manual_seed(0)\n",
        "train_size = int(0.85 * len(full_dataset))\n",
        "test_size = len(full_dataset) - train_size\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [train_size, test_size])\n",
        "'''\n",
        "MAKING DATASET ITERABLE\n",
        "'''\n",
        "num_epochs = num_iters / (len(train_dataset) / batch_size)\n",
        "num_epochs = int(num_epochs)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
        "                                           batch_size=batch_size, \n",
        "                                           shuffle=True)   # It's better to shuffle the whole training dataset! \n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
        "                                          batch_size=batch_size, \n",
        "                                          shuffle=False)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vuj6VlSn3BX4",
        "outputId": "8086fa71-f8ea-47f3-a4ea-4098e2a7ca5e"
      },
      "source": [
        "print(len(train_dataset))\n",
        "print(len(test_dataset))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16746\n",
            "2956\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AcQd9Kjm3Gg_",
        "outputId": "a16a1a40-90d4-4534-a61f-bc6835ea0adb"
      },
      "source": [
        "# One Image Size\n",
        "print(train_dataset[0][0].size())\n",
        "print(train_dataset[0][0].numpy().shape)\n",
        "# First Image Label\n",
        "print(train_dataset[0][1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 180, 180])\n",
            "(1, 180, 180)\n",
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtGvxK9j3Js2"
      },
      "source": [
        "#model 1\n",
        "class DeepNeuralNetworkModel(nn.Module):\n",
        "    def __init__(self, input_size, num_classes, num_hidden):\n",
        "        super().__init__()\n",
        "        ### 1st hidden layer: 784 --> 100\n",
        "        self.linear_1 = nn.Linear(input_size, num_hidden)\n",
        "        ### Non-linearity in 1st hidden layer\n",
        "        self.relu_1 = nn.ReLU()\n",
        "\n",
        "        ### 2nd hidden layer: 100 --> 100\n",
        "        self.linear_2 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 2nd hidden layer\n",
        "        self.relu_2 = nn.ReLU()\n",
        "\n",
        "        ### 3rd hidden layer: 100 --> 100\n",
        "        self.linear_3 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 3rd hidden layer\n",
        "        self.relu_3 = nn.ReLU()\n",
        "\n",
        "        ### 4th hidden layer: 100 --> 100\n",
        "        self.linear_4 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 3rd hidden layer\n",
        "        self.relu_4 = nn.ReLU()\n",
        "\n",
        "        ### 5th hidden layer: 100 --> 100\n",
        "        self.linear_5 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 3rd hidden layer\n",
        "        self.relu_5 = nn.ReLU()\n",
        "\n",
        "         ### 6th hidden layer: 100 --> 100\n",
        "        self.linear_6 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 3rd hidden layer\n",
        "        self.relu_6 = nn.ReLU()\n",
        "\n",
        "        ### Output layer: 100 --> 10\n",
        "        self.linear_out = nn.Linear(num_hidden, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        ### 1st hidden layer\n",
        "        out  = self.linear_1(x)\n",
        "        ### Non-linearity in 1st hidden layer\n",
        "        out = self.relu_1(out)\n",
        "        \n",
        "        ### 2nd hidden layer\n",
        "        out  = self.linear_2(out)\n",
        "        ### Non-linearity in 2nd hidden layer\n",
        "        out = self.relu_2(out)\n",
        "\n",
        "        ### 3rd hidden layer\n",
        "        out  = self.linear_3(out)\n",
        "        ### Non-linearity in 3rd hidden layer\n",
        "        out = self.relu_3(out)\n",
        "\n",
        "        ### 4th hidden layer\n",
        "        out  = self.linear_4(out)\n",
        "        ### Non-linearity in 3rd hidden layer\n",
        "        out = self.relu_4(out)\n",
        "        \n",
        "        ### 5th hidden layer\n",
        "        out  = self.linear_5(out)\n",
        "        ### Non-linearity in 3rd hidden layer\n",
        "        out = self.relu_5(out)\n",
        "        \n",
        "        ### 6th hidden layer\n",
        "        out  = self.linear_6(out)\n",
        "        ### Non-linearity in 3rd hidden layer\n",
        "        out = self.relu_6(out)\n",
        "        \n",
        "        # Linear layer (output)\n",
        "        probas  = self.linear_out(out)\n",
        "        return probas\n",
        "\n",
        "# INSTANTIATE MODEL CLASS\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhMK3JwV-eYy",
        "outputId": "d6626bfd-f27a-4696-dbcb-01247d2129ff"
      },
      "source": [
        "model = DeepNeuralNetworkModel(input_size = input_dim,\n",
        "                               num_classes = output_dim,\n",
        "                               num_hidden = num_hidden)\n",
        "# To enable GPU\n",
        "model.to(device)\n",
        "\n",
        "# INSTANTIATE LOSS & OPTIMIZER CLASS\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "iter = 0\n",
        "loss_list1 = []\n",
        "accuracy_list1 = []\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "\n",
        "        images = images.view(-1, 180*180).to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Clear gradients w.r.t. parameters\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass to get output/logits\n",
        "        outputs = model(images) \n",
        "\n",
        "        # Calculate Loss: softmax --> cross entropy loss\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Getting gradients w.r.t. parameters\n",
        "        loss.backward()\n",
        "\n",
        "        # Updating parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        iter += 1\n",
        "\n",
        "        if iter % 500 == 0:\n",
        "            # Calculate Accuracy         \n",
        "            correct = 0\n",
        "            total = 0\n",
        "            \n",
        "            # Iterate through test dataset\n",
        "            for images, labels in test_loader:\n",
        "               \n",
        "                images = images.view(-1, 180*180).to(device)\n",
        "\n",
        "                # Forward pass only to get logits/output\n",
        "                outputs = model(images)\n",
        "\n",
        "                # Get predictions from the maximum value\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "                # Total number of labels\n",
        "                total += labels.size(0)\n",
        "\n",
        "\n",
        "                # Total correct predictions\n",
        "                if torch.cuda.is_available():\n",
        "                    correct += (predicted.cpu() == labels.cpu()).sum() \n",
        "                else:\n",
        "                    correct += (predicted == labels).sum()\n",
        "\n",
        "            accuracy = 100 * correct.item() / total\n",
        "            loss_list1.append(loss.item())\n",
        "            accuracy_list1.append(accuracy)\n",
        "\n",
        "\n",
        "            # Print Loss\n",
        "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration: 500. Loss: 2.3066370487213135. Accuracy: 9.269282814614344\n",
            "Iteration: 1000. Loss: 2.297433376312256. Accuracy: 9.945872801082544\n",
            "Iteration: 1500. Loss: 2.3035435676574707. Accuracy: 9.709066305818673\n",
            "Iteration: 2000. Loss: 2.302886486053467. Accuracy: 9.573748308525033\n",
            "Iteration: 2500. Loss: 2.3014845848083496. Accuracy: 12.110960757780784\n",
            "Iteration: 3000. Loss: 2.302197217941284. Accuracy: 9.269282814614344\n",
            "Iteration: 3500. Loss: 2.2996649742126465. Accuracy: 9.269282814614344\n",
            "Iteration: 4000. Loss: 2.3069286346435547. Accuracy: 9.709066305818673\n",
            "Iteration: 4500. Loss: 2.3034279346466064. Accuracy: 9.573748308525033\n",
            "Iteration: 5000. Loss: 2.2986836433410645. Accuracy: 9.709066305818673\n",
            "Iteration: 5500. Loss: 2.296119213104248. Accuracy: 9.709066305818673\n",
            "Iteration: 6000. Loss: 2.2962493896484375. Accuracy: 9.573748308525033\n",
            "Iteration: 6500. Loss: 2.2944817543029785. Accuracy: 9.776725304465494\n",
            "Iteration: 7000. Loss: 2.301377773284912. Accuracy: 17.591339648173207\n",
            "Iteration: 7500. Loss: 2.299407958984375. Accuracy: 9.573748308525033\n",
            "Iteration: 8000. Loss: 2.305875778198242. Accuracy: 16.542625169147495\n",
            "Iteration: 8500. Loss: 2.3011651039123535. Accuracy: 21.312584573748307\n",
            "Iteration: 9000. Loss: 2.2872862815856934. Accuracy: 9.742895805142084\n",
            "Iteration: 9500. Loss: 2.3084280490875244. Accuracy: 15.257104194857916\n",
            "Iteration: 10000. Loss: 2.280283212661743. Accuracy: 9.641407307171853\n",
            "Iteration: 10500. Loss: 2.260265350341797. Accuracy: 10.520974289580515\n",
            "Iteration: 11000. Loss: 2.2808473110198975. Accuracy: 9.709066305818673\n",
            "Iteration: 11500. Loss: 2.354072093963623. Accuracy: 9.776725304465494\n",
            "Iteration: 12000. Loss: 2.2390635013580322. Accuracy: 13.294993234100135\n",
            "Iteration: 12500. Loss: 2.3554675579071045. Accuracy: 9.742895805142084\n",
            "Iteration: 13000. Loss: 2.2492246627807617. Accuracy: 10.013531799729364\n",
            "Iteration: 13500. Loss: 2.1895503997802734. Accuracy: 18.876860622462786\n",
            "Iteration: 14000. Loss: 2.260362386703491. Accuracy: 16.508795669824085\n",
            "Iteration: 14500. Loss: 2.1648201942443848. Accuracy: 10.588633288227335\n",
            "Iteration: 15000. Loss: 2.283229112625122. Accuracy: 11.637347767253045\n",
            "Iteration: 15500. Loss: 2.128762722015381. Accuracy: 21.14343707713126\n",
            "Iteration: 16000. Loss: 2.3261632919311523. Accuracy: 12.753721244925575\n",
            "Iteration: 16500. Loss: 2.1412129402160645. Accuracy: 18.166441136671178\n",
            "Iteration: 17000. Loss: 2.4734208583831787. Accuracy: 12.280108254397835\n",
            "Iteration: 17500. Loss: 2.100764274597168. Accuracy: 21.786197564276048\n",
            "Iteration: 18000. Loss: 2.187351703643799. Accuracy: 17.523680649526387\n",
            "Iteration: 18500. Loss: 2.0962777137756348. Accuracy: 11.806495263870096\n",
            "Iteration: 19000. Loss: 2.1073131561279297. Accuracy: 22.19215155615697\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "sz2Erhxw4ze1",
        "outputId": "7c291f14-63d9-41b0-ab43-e8d5c3f1ef3c"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "i = [(loss_list1.index(i)+1)*500 for i in loss_list1]\n",
        "\n",
        "plt.plot(i,loss_list1,label = \"Model 1 Loss\")\n",
        "plt.title('Iteration vs Loss')\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrZtlNGQFfVn"
      },
      "source": [
        "# Hyperparameters \n",
        "\n",
        "batch_size = 50\n",
        "num_iters = 100000\n",
        "input_dim = 28*28 # num_features = 784\n",
        "num_hidden = 100 # num of hidden nodes\n",
        "output_dim = 10\n",
        "\n",
        "learning_rate = 0.01  # More power so we can learn faster! previously it was 0.001\n",
        "\n",
        "# Device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LlaWM7LF0Aq"
      },
      "source": [
        "'''\n",
        "LOADING DATASET\n",
        "'''\n",
        "transform = transforms.Compose([\n",
        "                                transforms.Grayscale(),                                 \n",
        "                                transforms.Resize((28,28)),\n",
        "                                 transforms.ToTensor(),             \n",
        "                              ])\n",
        " \n",
        "full_dataset = dsets.ImageFolder(root='/content/training-a',transform= transform )\n",
        "\n",
        "torch.manual_seed(0)\n",
        "train_size = int(0.85 * len(full_dataset))\n",
        "test_size = len(full_dataset) - train_size\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [train_size, test_size])\n",
        "'''\n",
        "MAKING DATASET ITERABLE\n",
        "'''\n",
        "num_epochs = num_iters / (len(train_dataset) / batch_size)\n",
        "num_epochs = int(num_epochs)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
        "                                           batch_size=batch_size, \n",
        "                                           shuffle=True)   # It's better to shuffle the whole training dataset! \n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
        "                                          batch_size=batch_size, \n",
        "                                          shuffle=False)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99AxvTalFduv"
      },
      "source": [
        "#model 2\n",
        "class DeepNeuralNetworkModel2(nn.Module):\n",
        "    def __init__(self, input_size, num_classes, num_hidden):\n",
        "        super().__init__()\n",
        "        ### 1st hidden layer: 784 --> 100\n",
        "        self.linear_1 = nn.Linear(input_size, 720)\n",
        "        ### Non-linearity in 1st hidden layer\n",
        "        self.relu_1 = nn.ReLU()\n",
        "\n",
        "        ### 2nd hidden layer: 100 --> 100\n",
        "        self.linear_2 = nn.Linear(720, 360)\n",
        "        ### Non-linearity in 2nd hidden layer\n",
        "        self.relu_2 = nn.ReLU()\n",
        "\n",
        "        ### 3rd hidden layer: 100 --> 100\n",
        "        self.linear_3 = nn.Linear(360, 180)\n",
        "        ### Non-linearity in 3rd hidden layer\n",
        "        self.relu_3 = nn.ReLU()\n",
        "\n",
        "        ### Output layer: 100 --> 10\n",
        "        self.linear_out = nn.Linear(180, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        ### 1st hidden layer\n",
        "        out  = self.linear_1(x)\n",
        "        ### Non-linearity in 1st hidden layer\n",
        "        out = self.relu_1(out)\n",
        "        \n",
        "        ### 2nd hidden layer\n",
        "        out  = self.linear_2(out)\n",
        "        ### Non-linearity in 2nd hidden layer\n",
        "        out = self.relu_2(out)\n",
        "\n",
        "        ### 3rd hidden layer\n",
        "        out  = self.linear_3(out)\n",
        "        ### Non-linearity in 3rd hidden layer\n",
        "        out = self.relu_3(out)\n",
        "\n",
        "       \n",
        "         # Linear layer (output)\n",
        "        probas  = self.linear_out(out)\n",
        "        return probas\n",
        "\n",
        "# INSTANTIATE MODEL CLASS\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ad15Ijz4F4Zm",
        "outputId": "d511b3ec-2fed-4274-87e4-f8b6cf930f98"
      },
      "source": [
        "model = DeepNeuralNetworkModel2(input_size = input_dim,\n",
        "                               num_classes = output_dim,\n",
        "                               num_hidden = num_hidden)\n",
        "# To enable GPU\n",
        "model.to(device)\n",
        "\n",
        "# INSTANTIATE LOSS & OPTIMIZER CLASS\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "iter = 0\n",
        "#loadedModel = torch.load('/content/drive/MyDrive/Soft_Computing/Assignment2/exp1_model2-iteration-100188.pt')\n",
        "#iter = loadedModel['iter']\n",
        "#epoch=  loadedModel['epoch']\n",
        "#model.load_state_dict(loadedModel['model_state'])\n",
        "#model.eval()\n",
        "\n",
        "loss_list1_2 = []\n",
        "accuracy_list1_2 = []\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "\n",
        "        images = images.view(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Clear gradients w.r.t. parameters\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass to get output/logits\n",
        "        outputs = model(images) \n",
        "\n",
        "        # Calculate Loss: softmax --> cross entropy loss\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Getting gradients w.r.t. parameters\n",
        "        loss.backward()\n",
        "\n",
        "        # Updating parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        iter += 1\n",
        "\n",
        "        if iter % 500 == 0:\n",
        "            # Calculate Accuracy         \n",
        "            correct = 0\n",
        "            total = 0\n",
        "            # Iterate through test dataset\n",
        "            for images, labels in test_loader:\n",
        "               \n",
        "                images = images.view(-1, 28*28).to(device)\n",
        "\n",
        "                # Forward pass only to get logits/output\n",
        "                outputs = model(images)\n",
        "\n",
        "                # Get predictions from the maximum value\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "                # Total number of labels\n",
        "                total += labels.size(0)\n",
        "\n",
        "\n",
        "                # Total correct predictions\n",
        "                if torch.cuda.is_available():\n",
        "                    correct += (predicted.cpu() == labels.cpu()).sum() \n",
        "                else:\n",
        "                    correct += (predicted == labels).sum()\n",
        "\n",
        "            \n",
        "            accuracy = 100 * correct.item() / total\n",
        "            loss_list1_2.append(loss.item())\n",
        "            accuracy_list1_2.append(accuracy)\n",
        "\n",
        "            # Print Loss\n",
        "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration: 500. Loss: 2.307987928390503. Accuracy: 9.641407307171853\n",
            "Iteration: 1000. Loss: 2.3036327362060547. Accuracy: 10.757780784844384\n",
            "Iteration: 1500. Loss: 2.3034090995788574. Accuracy: 15.798376184032476\n",
            "Iteration: 2000. Loss: 2.2977986335754395. Accuracy: 9.878213802435724\n",
            "Iteration: 2500. Loss: 2.300408124923706. Accuracy: 12.787550744248986\n",
            "Iteration: 3000. Loss: 2.2965707778930664. Accuracy: 9.945872801082544\n",
            "Iteration: 3500. Loss: 2.3006067276000977. Accuracy: 17.523680649526387\n",
            "Iteration: 4000. Loss: 2.294069766998291. Accuracy: 10.182679296346414\n",
            "Iteration: 4500. Loss: 2.2940311431884766. Accuracy: 10.385656292286875\n",
            "Iteration: 5000. Loss: 2.2987060546875. Accuracy: 15.358592692828147\n",
            "Iteration: 5500. Loss: 2.2805135250091553. Accuracy: 10.588633288227335\n",
            "Iteration: 6000. Loss: 2.2570412158966064. Accuracy: 18.26792963464141\n",
            "Iteration: 6500. Loss: 2.2602431774139404. Accuracy: 18.843031123139376\n",
            "Iteration: 7000. Loss: 2.1928510665893555. Accuracy: 10.317997293640055\n",
            "Iteration: 7500. Loss: 2.230586051940918. Accuracy: 15.527740189445197\n",
            "Iteration: 8000. Loss: 2.197585344314575. Accuracy: 16.745602165087956\n",
            "Iteration: 8500. Loss: 2.16752552986145. Accuracy: 20.63599458728011\n",
            "Iteration: 9000. Loss: 2.226698637008667. Accuracy: 27.943166441136672\n",
            "Iteration: 9500. Loss: 2.272847890853882. Accuracy: 14.039242219215156\n",
            "Iteration: 10000. Loss: 2.069567918777466. Accuracy: 12.449255751014885\n",
            "Iteration: 10500. Loss: 2.0950472354888916. Accuracy: 25.74424898511502\n",
            "Iteration: 11000. Loss: 2.0097930431365967. Accuracy: 22.90257104194858\n",
            "Iteration: 11500. Loss: 1.9151968955993652. Accuracy: 28.95805142083897\n",
            "Iteration: 12000. Loss: 2.2350540161132812. Accuracy: 28.179972936400542\n",
            "Iteration: 12500. Loss: 1.9450407028198242. Accuracy: 31.25845737483085\n",
            "Iteration: 13000. Loss: 2.126809597015381. Accuracy: 24.52638700947226\n",
            "Iteration: 13500. Loss: 2.085921049118042. Accuracy: 20.027063599458728\n",
            "Iteration: 14000. Loss: 2.176361560821533. Accuracy: 37.41542625169148\n",
            "Iteration: 14500. Loss: 1.8959710597991943. Accuracy: 25.03382949932341\n",
            "Iteration: 15000. Loss: 1.802239179611206. Accuracy: 33.72801082543978\n",
            "Iteration: 15500. Loss: 1.773073434829712. Accuracy: 22.023004059539918\n",
            "Iteration: 16000. Loss: 1.8767976760864258. Accuracy: 22.90257104194858\n",
            "Iteration: 16500. Loss: 1.787590742111206. Accuracy: 48.54533152909337\n",
            "Iteration: 17000. Loss: 1.7898359298706055. Accuracy: 40.76454668470907\n",
            "Iteration: 17500. Loss: 2.0592339038848877. Accuracy: 22.69959404600812\n",
            "Iteration: 18000. Loss: 1.7095341682434082. Accuracy: 28.585926928281463\n",
            "Iteration: 18500. Loss: 1.5705012083053589. Accuracy: 46.78619756427605\n",
            "Iteration: 19000. Loss: 1.920241355895996. Accuracy: 21.718538565629228\n",
            "Iteration: 19500. Loss: 1.7653541564941406. Accuracy: 29.16102841677943\n",
            "Iteration: 20000. Loss: 1.875020146369934. Accuracy: 40.62922868741543\n",
            "Iteration: 20500. Loss: 1.8498718738555908. Accuracy: 34.43843031123139\n",
            "Iteration: 21000. Loss: 1.8401833772659302. Accuracy: 28.75507442489851\n",
            "Iteration: 21500. Loss: 2.367382287979126. Accuracy: 36.60351826792964\n",
            "Iteration: 22000. Loss: 1.6022329330444336. Accuracy: 39.174560216508794\n",
            "Iteration: 22500. Loss: 1.596760869026184. Accuracy: 43.437077131258455\n",
            "Iteration: 23000. Loss: 1.505768895149231. Accuracy: 42.929634641407304\n",
            "Iteration: 23500. Loss: 1.6306908130645752. Accuracy: 33.4573748308525\n",
            "Iteration: 24000. Loss: 1.2806895971298218. Accuracy: 49.15426251691475\n",
            "Iteration: 24500. Loss: 1.3415457010269165. Accuracy: 45.70365358592693\n",
            "Iteration: 25000. Loss: 1.7657526731491089. Accuracy: 42.625169147496614\n",
            "Iteration: 25500. Loss: 1.3237957954406738. Accuracy: 54.19485791610284\n",
            "Iteration: 26000. Loss: 1.2790751457214355. Accuracy: 46.41407307171854\n",
            "Iteration: 26500. Loss: 2.0991220474243164. Accuracy: 40.020297699594046\n",
            "Iteration: 27000. Loss: 1.9079211950302124. Accuracy: 44.2489851150203\n",
            "Iteration: 27500. Loss: 1.4982588291168213. Accuracy: 51.11637347767253\n",
            "Iteration: 28000. Loss: 1.7531378269195557. Accuracy: 55.31123139377537\n",
            "Iteration: 28500. Loss: 1.5070205926895142. Accuracy: 55.31123139377537\n",
            "Iteration: 29000. Loss: 1.6065024137496948. Accuracy: 26.082543978349122\n",
            "Iteration: 29500. Loss: 1.649570107460022. Accuracy: 39.884979702300406\n",
            "Iteration: 30000. Loss: 1.8545795679092407. Accuracy: 52.74018944519621\n",
            "Iteration: 30500. Loss: 1.7143632173538208. Accuracy: 49.52638700947226\n",
            "Iteration: 31000. Loss: 1.1967757940292358. Accuracy: 57.273342354533156\n",
            "Iteration: 31500. Loss: 1.1310906410217285. Accuracy: 47.42895805142084\n",
            "Iteration: 32000. Loss: 1.6535001993179321. Accuracy: 54.93910690121786\n",
            "Iteration: 32500. Loss: 1.356699824333191. Accuracy: 52.67253044654939\n",
            "Iteration: 33000. Loss: 1.8193342685699463. Accuracy: 38.971583220568334\n",
            "Iteration: 33500. Loss: 1.157939076423645. Accuracy: 61.97564276048715\n",
            "Iteration: 34000. Loss: 1.4789730310440063. Accuracy: 45.19621109607578\n",
            "Iteration: 34500. Loss: 1.2341536283493042. Accuracy: 54.16102841677943\n",
            "Iteration: 35000. Loss: 2.6681647300720215. Accuracy: 18.40324763193505\n",
            "Iteration: 35500. Loss: 1.2443469762802124. Accuracy: 62.04330175913397\n",
            "Iteration: 36000. Loss: 1.21913743019104. Accuracy: 50.43978349120433\n",
            "Iteration: 36500. Loss: 1.4091060161590576. Accuracy: 59.64140730717185\n",
            "Iteration: 37000. Loss: 1.0306825637817383. Accuracy: 58.08525033829499\n",
            "Iteration: 37500. Loss: 0.9785993695259094. Accuracy: 54.29634641407307\n",
            "Iteration: 38000. Loss: 1.1768536567687988. Accuracy: 60.453315290933695\n",
            "Iteration: 38500. Loss: 1.2839751243591309. Accuracy: 63.15967523680649\n",
            "Iteration: 39000. Loss: 1.1917510032653809. Accuracy: 58.89715832205683\n",
            "Iteration: 39500. Loss: 1.7128779888153076. Accuracy: 51.55615696887686\n",
            "Iteration: 40000. Loss: 0.9798657298088074. Accuracy: 62.28010825439784\n",
            "Iteration: 40500. Loss: 1.2253466844558716. Accuracy: 69.68876860622463\n",
            "Iteration: 41000. Loss: 1.156457781791687. Accuracy: 64.14073071718539\n",
            "Iteration: 41500. Loss: 1.6263257265090942. Accuracy: 62.61840324763193\n",
            "Iteration: 42000. Loss: 1.0493381023406982. Accuracy: 63.05818673883626\n",
            "Iteration: 42500. Loss: 1.1031010150909424. Accuracy: 63.937753721244924\n",
            "Iteration: 43000. Loss: 1.1891183853149414. Accuracy: 65.59539918809202\n",
            "Iteration: 43500. Loss: 1.4104713201522827. Accuracy: 59.945872801082544\n",
            "Iteration: 44000. Loss: 1.208332896232605. Accuracy: 46.92151556156969\n",
            "Iteration: 44500. Loss: 0.9471487998962402. Accuracy: 64.14073071718539\n",
            "Iteration: 45000. Loss: 0.9120197296142578. Accuracy: 68.40324763193505\n",
            "Iteration: 45500. Loss: 0.8275438547134399. Accuracy: 73.17320703653586\n",
            "Iteration: 46000. Loss: 0.9152075052261353. Accuracy: 69.68876860622463\n",
            "Iteration: 46500. Loss: 0.883059024810791. Accuracy: 70.33152909336941\n",
            "Iteration: 47000. Loss: 1.1999139785766602. Accuracy: 66.914749661705\n",
            "Iteration: 47500. Loss: 0.7878946661949158. Accuracy: 70.23004059539919\n",
            "Iteration: 48000. Loss: 1.134924054145813. Accuracy: 69.82408660351827\n",
            "Iteration: 48500. Loss: 0.9966741800308228. Accuracy: 60.487144790257105\n",
            "Iteration: 49000. Loss: 1.2498993873596191. Accuracy: 50.37212449255751\n",
            "Iteration: 49500. Loss: 0.6556713581085205. Accuracy: 72.25981055480379\n",
            "Iteration: 50000. Loss: 0.6647794246673584. Accuracy: 74.15426251691476\n",
            "Iteration: 50500. Loss: 0.6539930105209351. Accuracy: 70.63599458728011\n",
            "Iteration: 51000. Loss: 0.7125394940376282. Accuracy: 73.78213802435724\n",
            "Iteration: 51500. Loss: 0.8051477074623108. Accuracy: 75.6765899864682\n",
            "Iteration: 52000. Loss: 0.7851148843765259. Accuracy: 72.32746955345061\n",
            "Iteration: 52500. Loss: 0.8178499341011047. Accuracy: 72.56427604871448\n",
            "Iteration: 53000. Loss: 0.576403796672821. Accuracy: 76.89445196211096\n",
            "Iteration: 53500. Loss: 0.7262112498283386. Accuracy: 71.65087956698241\n",
            "Iteration: 54000. Loss: 0.9871160984039307. Accuracy: 75.54127198917456\n",
            "Iteration: 54500. Loss: 0.8152483105659485. Accuracy: 74.9661705006766\n",
            "Iteration: 55000. Loss: 1.1325082778930664. Accuracy: 70.39918809201623\n",
            "Iteration: 55500. Loss: 0.8799983859062195. Accuracy: 56.732070365358595\n",
            "Iteration: 56000. Loss: 0.5659212470054626. Accuracy: 75.0338294993234\n",
            "Iteration: 56500. Loss: 0.646018385887146. Accuracy: 77.57104194857916\n",
            "Iteration: 57000. Loss: 0.8398472666740417. Accuracy: 78.55209742895805\n",
            "Iteration: 57500. Loss: 0.985935389995575. Accuracy: 77.16508795669824\n",
            "Iteration: 58000. Loss: 0.6003590226173401. Accuracy: 79.16102841677943\n",
            "Iteration: 58500. Loss: 0.5829305648803711. Accuracy: 68.40324763193505\n",
            "Iteration: 59000. Loss: 0.7754631638526917. Accuracy: 74.69553450608932\n",
            "Iteration: 59500. Loss: 0.7912197709083557. Accuracy: 72.80108254397835\n",
            "Iteration: 60000. Loss: 0.526229739189148. Accuracy: 77.60487144790257\n",
            "Iteration: 60500. Loss: 0.5477401614189148. Accuracy: 79.56698240866035\n",
            "Iteration: 61000. Loss: 0.3890812397003174. Accuracy: 80.92016238159675\n",
            "Iteration: 61500. Loss: 0.6772533655166626. Accuracy: 79.97293640054127\n",
            "Iteration: 62000. Loss: 1.2880443334579468. Accuracy: 56.393775372124495\n",
            "Iteration: 62500. Loss: 0.9346334338188171. Accuracy: 55.48037889039242\n",
            "Iteration: 63000. Loss: 0.52521812915802. Accuracy: 79.43166441136671\n",
            "Iteration: 63500. Loss: 1.28751802444458. Accuracy: 73.74830852503383\n",
            "Iteration: 64000. Loss: 0.6225088238716125. Accuracy: 81.3937753721245\n",
            "Iteration: 64500. Loss: 0.6493165493011475. Accuracy: 82.51014884979702\n",
            "Iteration: 65000. Loss: 0.7281244397163391. Accuracy: 64.24221921515561\n",
            "Iteration: 65500. Loss: 1.2557674646377563. Accuracy: 69.51962110960758\n",
            "Iteration: 66000. Loss: 0.4996393918991089. Accuracy: 79.66847090663059\n",
            "Iteration: 66500. Loss: 0.5793619155883789. Accuracy: 75.3382949932341\n",
            "Iteration: 67000. Loss: 0.668295681476593. Accuracy: 75.3382949932341\n",
            "Iteration: 67500. Loss: 0.4707604944705963. Accuracy: 82.54397834912044\n",
            "Iteration: 68000. Loss: 0.6518294811248779. Accuracy: 79.33017591339649\n",
            "Iteration: 68500. Loss: 1.0883262157440186. Accuracy: 68.97834912043302\n",
            "Iteration: 69000. Loss: 0.4589286148548126. Accuracy: 81.765899864682\n",
            "Iteration: 69500. Loss: 0.6314113736152649. Accuracy: 77.63870094722598\n",
            "Iteration: 70000. Loss: 0.6201218962669373. Accuracy: 75.60893098782138\n",
            "Iteration: 70500. Loss: 0.9039111137390137. Accuracy: 80.0744248985115\n",
            "Iteration: 71000. Loss: 0.5652816891670227. Accuracy: 81.66441136671178\n",
            "Iteration: 71500. Loss: 0.46609801054000854. Accuracy: 84.74289580514208\n",
            "Iteration: 72000. Loss: 1.1456471681594849. Accuracy: 70.50067658998647\n",
            "Iteration: 72500. Loss: 0.6004699468612671. Accuracy: 79.46549391069013\n",
            "Iteration: 73000. Loss: 1.0517877340316772. Accuracy: 71.51556156968877\n",
            "Iteration: 73500. Loss: 0.35279881954193115. Accuracy: 81.56292286874154\n",
            "Iteration: 74000. Loss: 0.4274313747882843. Accuracy: 82.4424898511502\n",
            "Iteration: 74500. Loss: 0.4054974615573883. Accuracy: 83.28822733423546\n",
            "Iteration: 75000. Loss: 0.45261695981025696. Accuracy: 78.17997293640055\n",
            "Iteration: 75500. Loss: 0.36759212613105774. Accuracy: 82.4086603518268\n",
            "Iteration: 76000. Loss: 0.4065355956554413. Accuracy: 84.50608930987822\n",
            "Iteration: 76500. Loss: 0.7101297974586487. Accuracy: 76.55615696887686\n",
            "Iteration: 77000. Loss: 0.4628261923789978. Accuracy: 84.33694181326116\n",
            "Iteration: 77500. Loss: 0.5688516497612. Accuracy: 82.91610284167794\n",
            "Iteration: 78000. Loss: 0.979494035243988. Accuracy: 52.77401894451962\n",
            "Iteration: 78500. Loss: 1.550642728805542. Accuracy: 58.82949932341001\n",
            "Iteration: 79000. Loss: 0.5764927864074707. Accuracy: 81.765899864682\n",
            "Iteration: 79500. Loss: 0.41289401054382324. Accuracy: 84.06630581867388\n",
            "Iteration: 80000. Loss: 0.5023386478424072. Accuracy: 83.1190798376184\n",
            "Iteration: 80500. Loss: 0.3066200613975525. Accuracy: 83.59269282814614\n",
            "Iteration: 81000. Loss: 0.3954295217990875. Accuracy: 87.07713125845737\n",
            "Iteration: 81500. Loss: 0.3981829583644867. Accuracy: 86.26522327469553\n",
            "Iteration: 82000. Loss: 0.4065881073474884. Accuracy: 84.06630581867388\n",
            "Iteration: 82500. Loss: 0.5480163097381592. Accuracy: 80.78484438430311\n",
            "Iteration: 83000. Loss: 0.43417561054229736. Accuracy: 85.38565629228687\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-c8bf04c884e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0maccuracy_list1_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m             \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0mPIL\u001b[0m \u001b[0mImage\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRescaled\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \"\"\"\n\u001b[0;32m--> 297\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mantialias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation, max_size, antialias)\u001b[0m\n\u001b[1;32m    399\u001b[0m             )\n\u001b[1;32m    400\u001b[0m         \u001b[0mpil_interpolation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_modes_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF_pil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpil_interpolation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mF_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mantialias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mantialias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional_pil.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation, max_size)\u001b[0m\n\u001b[1;32m    239\u001b[0m                 \u001b[0;34m\"i.e. size should be an int or a sequence of length 1 in torchscript mode.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m             )\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   1903\u001b[0m                 )\n\u001b[1;32m   1904\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1905\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1906\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1907\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36m_new\u001b[0;34m(self, im)\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0mnew\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m         \u001b[0mnew\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m         \u001b[0mnew\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"P\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"PA\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpalette\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "XmTQppPaHw6q",
        "outputId": "61980685-d886-4228-cb58-36dcfc77b149"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "itr = [(loss_list1_2.index(i)+1)*500 for i in loss_list1_2]\n",
        "\n",
        "plt.plot(itr,loss_list1_2)\n",
        "plt.title('Iteration vs Loss')\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend('Loss Curve',loc='best')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tJtVFfk1eSm",
        "outputId": "bff2ade5-f72c-41a5-f133-39ac573bb661"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('./drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at ./drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlgIZH331eqd"
      },
      "source": [
        "dest ='/content/drive/MyDrive/SoftComputing Assignment 2/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zypjjZnM2ZwO"
      },
      "source": [
        "with open(dest+\"model1_exp1.txt\", \"w\") as output:\n",
        "    output.write(str(loss_list1))\n",
        "    output.write('\\n')\n",
        "    output.write(str(accuracy_list1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlVdfrV11gbt"
      },
      "source": [
        "path=dest\n",
        "path += f\"exp1_model2-iteration-{iter}.pt\"\n",
        "save_obj = {\n",
        "\n",
        "       'epoch': epoch,\n",
        "       'iter': iter,\n",
        "       'model_state': model.state_dict(),\n",
        "       'optimizer_state': optimizer.state_dict(),       \n",
        "       }\n",
        "torch.save(model.state_dict(), path)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yzdXvNS9UDE"
      },
      "source": [
        "with open(dest+\"model2_exp1.txt\", \"w\") as output:\n",
        "    output.write(str(loss_list1_2))\n",
        "    output.write('\\n')\n",
        "    output.write(str(accuracy_list1_2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHX1__bkF1PV"
      },
      "source": [
        "Given dataset 2 Experiment "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yihjRzt7w0Aj"
      },
      "source": [
        "!pip install idx2numpy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0m2SoneFwIfp"
      },
      "source": [
        "#train dataset 2\n",
        "import numpy as np\n",
        "import idx2numpy\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "    \n",
        "imagefile = '/content/Dataset_2/train-images-idx3-ubyte'\n",
        "imagearray = idx2numpy.convert_from_file(imagefile)\n",
        "print(imagearray[0].shape)\n",
        "labels_path = '/content/Dataset_2/train-labels-idx1-ubyte'\n",
        "labels = idx2numpy.convert_from_file(labels_path)\n",
        "labels[0]\n",
        "\n",
        "train_d2='/content/Dataset_2/train'\n",
        "if(not os.path.isdir(train_d2)):\n",
        "  os.makedirs(train_d2)\n",
        "\n",
        "\n",
        "for i in range(len(labels)):\n",
        "  pixels = np.array(imagearray[i], dtype='uint8')\n",
        "\n",
        "    # Reshape the array into 28 x 28 array (2-dimensional array)\n",
        " # pixels = pixels.reshape((28, 28))\n",
        "  if(not os.path.isdir(train_d2+'/'+str(labels[i]))):\n",
        "      os.makedirs(train_d2+'/'+str(labels[i]))\n",
        "\n",
        "  n = len(os.listdir(train_d2+'/'+str(labels[i])))+1\n",
        "  \n",
        "  im = Image.fromarray(pixels)\n",
        "  im.save(train_d2+'/'+str(labels[i])+'/'+str(n)+'.png')\n",
        "\n",
        "  \n",
        "  \n",
        "\n",
        "#plt.imshow(imagearray[4], cmap=plt.cm.binary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXixRP1RICMB"
      },
      "source": [
        "#test dataset 2\n",
        "import numpy as np\n",
        "import idx2numpy\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "    \n",
        "imagefile = '/content/Dataset_2/t10k-images-idx3-ubyte'\n",
        "imagearray = idx2numpy.convert_from_file(imagefile)\n",
        "print(imagearray[0].shape)\n",
        "labels_path = '/content/Dataset_2/t10k-labels-idx1-ubyte'\n",
        "labels = idx2numpy.convert_from_file(labels_path)\n",
        "labels[0]\n",
        "\n",
        "ds2='/content/Dataset_2/test'\n",
        "if(not os.path.isdir(ds2)):\n",
        "  os.makedirs(ds2)\n",
        "\n",
        "\n",
        "for i in range(len(labels)):\n",
        "  pixels = np.array(imagearray[i], dtype='uint8')\n",
        "\n",
        "    # Reshape the array into 28 x 28 array (2-dimensional array)\n",
        " # pixels = pixels.reshape((28, 28))\n",
        "  if(not os.path.isdir(ds2+'/'+str(labels[i]))):\n",
        "      os.makedirs(ds2+'/'+str(labels[i]))\n",
        "\n",
        "  n = len(os.listdir(ds2+'/'+str(labels[i])))+1\n",
        "  \n",
        "  im = Image.fromarray(pixels)\n",
        "  im.save(ds2+'/'+str(labels[i])+'/'+str(n)+'.png')\n",
        "\n",
        "  \n",
        "  \n",
        "\n",
        "#plt.imshow(imagearray[4], cmap=plt.cm.binary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zh0_ADeP8pMs"
      },
      "source": [
        "# Hyperparameters for exp 1\n",
        "\n",
        "batch_size = 20\n",
        "num_iters = 20000\n",
        "input_dim = 28*28 # num_features = 784\n",
        "num_hidden = 200 # num of hidden nodes\n",
        "output_dim = 10\n",
        "\n",
        "learning_rate = 0.01  # More power so we can learn faster! previously it was 0.001\n",
        "\n",
        "# Device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KK5CEPda-LAH"
      },
      "source": [
        "'''\n",
        "LOADING DATASET\n",
        "'''\n",
        "transform = transforms.Compose([\n",
        "                                transforms.Grayscale(),                                 \n",
        "                                transforms.ToTensor() \n",
        "                                ])\n",
        " \n",
        "train_dataset = dsets.ImageFolder(root='/content/Dataset_2/train',transform= transform )\n",
        "test_dataset = dsets.ImageFolder(root='/content/Dataset_2/test',transform= transform )\n",
        "\n",
        "\n",
        "'''\n",
        "MAKING DATASET ITERABLE\n",
        "'''\n",
        "num_epochs = num_iters / (len(train_dataset) / batch_size)\n",
        "num_epochs = int(num_epochs)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
        "                                           batch_size=batch_size, \n",
        "                                           shuffle=True)   # It's better to shuffle the whole training dataset! \n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
        "                                          batch_size=batch_size, \n",
        "                                          shuffle=False)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQGVhnAY81Wr"
      },
      "source": [
        "print(len(train_dataset))\n",
        "print(len(test_dataset))\n",
        "# One Image Size\n",
        "print(train_dataset[0][0].size())\n",
        "print(train_dataset[0][0].numpy().shape)\n",
        "# First Image Label\n",
        "print(train_dataset[0][1])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGFNud4m-Qli"
      },
      "source": [
        "model = DeepNeuralNetworkModel(input_size = input_dim,\n",
        "                               num_classes = output_dim,\n",
        "                               num_hidden = num_hidden)\n",
        "# To enable GPU\n",
        "model.to(device)\n",
        "\n",
        "# INSTANTIATE LOSS & OPTIMIZER CLASS\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "iter = 0\n",
        "loss_list2 = []\n",
        "accuracy_list2 = []\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "\n",
        "        images = images.view(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Clear gradients w.r.t. parameters\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass to get output/logits\n",
        "        outputs = model(images) \n",
        "\n",
        "        # Calculate Loss: softmax --> cross entropy loss\n",
        "        loss = criterion(outputs, labels)\n",
        "       \n",
        "\n",
        "        # Getting gradients w.r.t. parameters\n",
        "        loss.backward()\n",
        "\n",
        "        # Updating parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        iter += 1\n",
        "\n",
        "        if iter % 500 == 0:\n",
        "            # Calculate Accuracy         \n",
        "            correct = 0\n",
        "            total = 0\n",
        "            \n",
        "            # Iterate through test dataset\n",
        "            for images, labels in test_loader:\n",
        "               \n",
        "                images = images.view(-1, 28*28).to(device)\n",
        "\n",
        "                # Forward pass only to get logits/output\n",
        "                outputs = model(images)\n",
        "\n",
        "                # Get predictions from the maximum value\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "                # Total number of labels\n",
        "                total += labels.size(0)\n",
        "                \n",
        "\n",
        "                # Total correct predictions\n",
        "                if torch.cuda.is_available():\n",
        "                    correct += (predicted.cpu() == labels.cpu()).sum() \n",
        "                else:\n",
        "                    correct += (predicted == labels).sum()\n",
        "\n",
        "            accuracy = 100 * correct.item() / total\n",
        "            loss_list2.append(loss.item())\n",
        "            accuracy_list2.append(accuracy)\n",
        "\n",
        "\n",
        "            # Print Loss\n",
        "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RlrsJFRAS03"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "itr = [(loss_list2.index(i)+1)*500 for i in loss_list2]\n",
        "\n",
        "plt.plot(itr,loss_list2)\n",
        "plt.title('Iteration vs Loss')\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend('Loss Curve',loc='best')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oc62YWUuLVl4"
      },
      "source": [
        "# Hyperparameters for exp 2\n",
        "\n",
        "batch_size = 100\n",
        "num_iters = 50000\n",
        "input_dim = 28*28 # num_features = 784\n",
        "num_hidden = 100 # num of hidden nodes\n",
        "output_dim = 10\n",
        "\n",
        "learning_rate = 0.01  # More power so we can learn faster! previously it was 0.001\n",
        "\n",
        "# Device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "'''\n",
        "MAKING DATASET ITERABLE\n",
        "'''\n",
        "num_epochs = num_iters / (len(train_dataset) / batch_size)\n",
        "num_epochs = int(num_epochs)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
        "                                           batch_size=batch_size, \n",
        "                                           shuffle=True)   # It's better to shuffle the whole training dataset! \n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
        "                                          batch_size=batch_size, \n",
        "                                          shuffle=False)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "os8ILVdsK9I8"
      },
      "source": [
        "model = DeepNeuralNetworkModel2(input_size = input_dim,\n",
        "                               num_classes = output_dim,\n",
        "                               num_hidden = num_hidden)\n",
        "# To enable GPU\n",
        "model.to(device)\n",
        "\n",
        "# INSTANTIATE LOSS & OPTIMIZER CLASS\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "iter = 0\n",
        "loss_list2_2 = []\n",
        "accuracy_list2_2 = []\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "\n",
        "        images = images.view(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Clear gradients w.r.t. parameters\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass to get output/logits\n",
        "        outputs = model(images) \n",
        "\n",
        "        # Calculate Loss: softmax --> cross entropy loss\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "\n",
        "        # Getting gradients w.r.t. parameters\n",
        "        loss.backward()\n",
        "\n",
        "        # Updating parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        iter += 1\n",
        "\n",
        "        if iter % 500 == 0:\n",
        "            # Calculate Accuracy         \n",
        "            correct = 0\n",
        "            total = 0\n",
        "            # Iterate through test dataset\n",
        "            for images, labels in test_loader:\n",
        "               \n",
        "                images = images.view(-1, 28*28).to(device)\n",
        "\n",
        "                # Forward pass only to get logits/output\n",
        "                outputs = model(images)\n",
        "\n",
        "                # Get predictions from the maximum value\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "                # Total number of labels\n",
        "                total += labels.size(0)\n",
        "\n",
        "\n",
        "                # Total correct predictions\n",
        "                if torch.cuda.is_available():\n",
        "                    correct += (predicted.cpu() == labels.cpu()).sum() \n",
        "                else:\n",
        "                    correct += (predicted == labels).sum()\n",
        "\n",
        "            accuracy = 100 * correct.item() / total\n",
        "            loss_list2_2.append(loss.item())\n",
        "            accuracy_list2_2.append(accuracy)\n",
        "\n",
        "\n",
        "            # Print Loss\n",
        "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNYkXSQHMHD-"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "itr = [(loss_list2_2.index(i)+1)*500 for i in loss_list2_2]\n",
        "\n",
        "plt.plot(itr,loss_list2_2)\n",
        "plt.title('Iteration vs Loss')\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend('Loss Curve',loc='best')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pqElYkRf2ad"
      },
      "source": [
        "# **Visualization of Comparison**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdMRoTltf8CW"
      },
      "source": [
        "m1_exp1_path='/content/drive/MyDrive/SoftComputing Assignment 2/model1_exp1.txt'\n",
        "m2_exp1_path='/content/drive/MyDrive/SoftComputing Assignment 2/model2_exp1.txt'\n",
        "\n",
        "m1_exp2_path='/content/drive/MyDrive/SoftComputing Assignment 2/model1_exp2.txt'\n",
        "m2_exp2_path='/content/drive/MyDrive/SoftComputing Assignment 2/model2_exp2.txt'\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MU-cK8m5f9Vn"
      },
      "source": [
        "with open(m1_exp1_path) as f:\n",
        "    lines = f.read().splitlines()\n",
        "    m1_e1_loss =[float(x) for x in lines[0][1:-1].split(\", \")]\n",
        "    m1_e1_acc = [float(x) for x in lines[1][1:-1].split(\", \")]\n",
        "    print(m1_e1_acc)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DxMlEJkgBH3"
      },
      "source": [
        "with open(m2_exp1_path) as f:\n",
        "    lines = f.read().splitlines()\n",
        "    m2_e1_loss =[float(x) for x in lines[0][1:-1].split(\", \")]\n",
        "    m2_e1_acc = [float(x) for x in lines[1][1:-1].split(\", \")]\n",
        "    print(m2_e1_acc)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVFD09-bgE38"
      },
      "source": [
        "with open(m1_exp2_path) as f:\n",
        "    lines = f.read().splitlines()\n",
        "    m1_e2_loss =[float(x) for x in lines[0][1:-1].split(\", \")]\n",
        "    m1_e2_acc = [float(x) for x in lines[1][1:-1].split(\", \")]\n",
        "    print(m1_e2_acc)\n",
        "\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKZAnNXfgLOj"
      },
      "source": [
        "with open(m2_exp2_path) as f:\n",
        "    lines = f.read().splitlines()\n",
        "    m2_e2_loss =[float(x) for x in lines[0][1:-1].split(\", \")]\n",
        "    m2_e2_acc = [float(x) for x in lines[1][1:-1].split(\", \")]\n",
        "    print(m2_e2_acc)\n",
        "\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbXsam3KgNsg"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "itr = [(m1_e1_loss.index(i)+1)*500 for i in m1_e1_loss]\n",
        "\n",
        "plt.plot(itr,m1_e1_loss,label = \"Dataset 1\")\n",
        "\n",
        "itr = [(m1_e2_loss.index(i)+1)*500 for i in m1_e2_loss]\n",
        "\n",
        "plt.plot(itr,m1_e2_loss,label = \"Dataset 2\")\n",
        "\n",
        "plt.title('Iteration vs Loss')\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss comparison between two datasets(Model 1) ')\n",
        "# show a legend on the plot\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6RTR2VwgPh7"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "itr = [(m1_e1_acc.index(i)+1)*500 for i in m1_e1_acc]\n",
        "\n",
        "plt.plot(itr,m1_e1_acc,label = \"Dataset 1\")\n",
        "\n",
        "itr = [(m1_e2_acc.index(i)+1)*500 for i in m1_e2_acc]\n",
        "\n",
        "plt.plot(itr,m1_e2_acc,label = \"Dataset 2\")\n",
        "\n",
        "plt.title('Iteration vs Loss')\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Accuracy comparison between two datasets(Model 1) ')\n",
        "# show a legend on the plot\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrbJkLM9gSnK"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "itr = [(m2_e1_loss.index(i)+1)*500 for i in m2_e1_loss]\n",
        "\n",
        "plt.plot(itr,m2_e1_loss,label = \"Dataset 1\")\n",
        "\n",
        "itr = [(m2_e2_loss.index(i)+1)*500 for i in m2_e2_loss]\n",
        "\n",
        "plt.plot(itr,m2_e2_loss,label = \"Dataset 2\")\n",
        "\n",
        "plt.title('Iteration vs Loss')\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss comparison between two datasets(Model 2) ')\n",
        "# show a legend on the plot\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiiHwzc7gVY_"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "itr = [(m2_e1_acc.index(i)+1)*500 for i in m2_e1_acc]\n",
        "\n",
        "plt.plot(itr,m2_e1_acc,label = \"Dataset 1\")\n",
        "\n",
        "itr = [(m2_e2_acc.index(i)+1)*500 for i in m2_e2_acc]\n",
        "\n",
        "plt.plot(itr,m2_e2_acc,label = \"Dataset 2\")\n",
        "\n",
        "plt.title('Iteration vs Loss')\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Accuracy comparison between two datasets(Model 2) ')\n",
        "# show a legend on the plot\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}